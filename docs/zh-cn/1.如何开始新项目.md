
构建开始新项目基于以下3点：

1. 在问题定于以及数据清洗上已经用足够多时间。
2. 已经有一个训练和验证的pipeline，可以获得可用的结果
3. 已经选择认可的评估指标

## 1.1 模型结构选择

> 尽量重用一个已经可用且有效的模型结构

1. 首先选用开源的模型结构
2. 模型有很多超参数决定了模型的大小和其他细节（模型层数，层的宽度，激活函数）
    - 因此，选择架构实际上意味着选择一系列不同的模型（每个模型超参数设置一个）。 
    - 参数的设置分为两部分：1.初始参数设置；2.一个科学的方法提升模型表现
3. 如果可能的话，<font color=darkred>试着找到一篇尽可能接近当前问题的论文，并复制该模型作为起点</font>。

## 1.2 优化器选择

> 从当前问题类型的最流行优化器开始

1. 没有针对所有模型结构都最好的优化器，甚至[评估比对不同优化器的优劣也很困难](https://arxiv.org/abs/1910.05446)
2. 首先选用开源、业界常用的优化器、当前问题常用优化器
3. 关注所选优化器的所有超参数
    1. 具有更多参数的优化器，需要更多的调整才能找到较优参数
    2. 调整其他超参数的时候优化器参数不要动
    3. 可以优先用SGD和Adam作为优化器
4. 常用优化器
    1. SGD
    2. Adam NAdam

## 1.3 batch size设置

> batch大小影响训练速度但是不会直接影响验证集的效果。<font color=darkred>一般情况，在硬件配置允许下batch大小要设置足够大</font>

1. batch大小时决定使用资源大小、训练速度快慢的关键因素
2. 增大batch大小可以加快训练速度。十分有利于快速调参
3. 增加batch大小可能会减少、增加或不改变资源消耗
4. batch大小不应该作为提升模型在验证集上表现的超参数
    1. 所有参数调整完之后，不论多大的batch其结果表现都应该是一致的(see Shallue et al. 2018).


## 1.4 初始参数设置

1. 定义初始变量
    1. 模型配置：比如`hidden_layers_dim=[64, 64] `
    2. 优化器参数: 比如`lr=0.01`
    3. 训练的次数: 比如`num_epoches=15`
2. 配置初始参数需要训练运行和试错debug
3. 配置原则是简单，相对快速，相对资源消耗较少，获取较合理结果
    1. 简单：不要过早的增加复杂功能，会浪费时间在调试这些无用的功能上（比如：先用常数学习率 后在改用`decay schedules`学习率）
    2. 选择一个快速，资源消耗较少的配置，有利于超参数的调优（比如：首先用一个简单的模型）
    3. 合理结果：要好于随机模型表现
4. 设置训练次数需要权衡以下几点：
    1. 更多的训练次数可以使模型表现更好，有利于超参数调优(see Shallue et al. 2018)
    2. 更少的训练次数训练更快使用更少的资源，可以提高调整的效率
    3. 在初期选择了不必要的较大次数。后期将很难改变（比如，基于该次数调整设置了学习率）

