
# 3. 如何决定每次训练运行次数

1. 有两种类型的工作负载：受计算限制(`compute-bound`)的工作负载和不受计算约束的工作负载。
2. 当在计算约束(`compute-bound`)下进行训练的时候，训练约束取决于我们愿意等多久，而不是受限于我们有多少训练数据或其他因素。
    - 在这种情况下，如果我们能够以某种方式训练更长时间或更有效，我们应该会看到更低的训练损失，并且通过适当的调整，验证损失会得到改善。
    - 换句话说，加快训练相当于提高训练，“最佳”训练时间总是“只要我们能负担得起”
    - 也就是说，仅仅因为工作量有限，并不意味着训练时间更长/更快是提高结果的唯一途径。
3. 当训练不受计算限制时，我们可以随
    - 在这种情况下，我们应该期望能够训练到非常低的训练损失，训练时间越长可能会稍微减少训练损失，但不会有意义地减少验证损失。
    - 特别是当训练不受计算限制时，更慷慨的训练时间预算可以使调整更容易，尤其是在调整学习率衰减时间表时，因为它们与训练预算有特别强的交互作用
      - 换言之，非常吝啬的训练时间预算可能需要调整到完美的学习率衰减时间表，以实现良好的错误率。
4. 无论给定的工作量是否受计算限制，增加梯度（跨批次）方差的方法通常会导致训练进度变慢，因此可能会增加达到特定验证损失所需的训练步骤数。高梯度变化可能由以下原因引起：
    - 使用较小的`batch size`
    - 增加数据扩增
    - 增加了一些正则（比如`dropout`)

## 3.1 当训练不受计算限制时-决定训练时间

1. 我们的主要目标是确保我们训练的时间足够长，以使模型达到最佳结果，同时<font color=darkred>避免在训练步骤的数量上过度浪费</font>。
2. 当有疑问时，在训练的时间上犯错误。如果正确使用了回溯（最佳）检查点选择，并且检查点足够频繁，那么训练时间越长，性能就不会下降。
3. 切勿调整研究中的`max_train_steps`数。选择一个值并将其用于所有试验。从这些试验中，绘制回顾性检查点选择找到的训练步骤，以优化`max_train_steps`的选择。
   - 例如，如果最佳步数总是在训练的前10%，那么最大步数太高了。
   - 或者，如果最好的步骤始终在训练的最后25%，我们可能会从更长时间的训练和重新调整衰减时间表中受益。
4. 当体系结构或数据发生变化时（例如增加数据扩充），理想的训练步骤数可能会发生变化。
5. 下面我们将描述如何根据使用恒定学习率“完美匹配”训练集所需的步骤数来选择`max_train_steps`的初始候选值
    1. 注意，我们没有以精确或数学上定义良好的方式使用短语“完美匹配训练集”。这仅仅是一个非正式的描述，表示训练损失很低。
        - 例如，当使用对数损失进行训练时，如果没有正则化项，我们可能会看到训练损失一直在缓慢改善，直到我们达到浮点极限，因为网络权重无边界增长，并且训练集上模型的预测变得越来越自信。在这种情况下，我们可以说，在训练集上错误分类误差达到零时，模型“完全适合”训练集。
    2. 如果训练过程中的梯度噪声量增加，我们发现`max_train_steps`的起始值可能需要增加。
        - 例如，如果在模型中引入了数据扩充或正则化（如丢弃）。
    3. 如果训练过程在某种程度上有所改善，那么可以减少`max_train_steps`。
        - 例如，使用更好的优化程序或更好的学习率计划。

### 3.1.1 使用学习率扫描为`max_train_steps`选择初始候选的算法

The number of steps required for the fastest trial in the sweep to reach perfect training performance is our initial guess for max_train_steps.

1. 该程序假设不仅可以“完美”地适应训练集，而且可以使用恒定的学习率计划表。
2. 如果可以完美地匹配整个训练集，那么必须存在一个完美地匹配训练集的配置（具有一些max_train_steps值）；找到任何这样的配置，并使用其max_train_steps值作为起点N。
3. 运行恒定的学习率扫描（即网格搜索学习率），无需数据扩充和正则化，其中每个试验训练N个步骤。
4. 我们对max_train_steps的初步使用可达到完美的训练表现，运行最快的所需的步数。
5. 注意：糟糕的搜索空间可能会让人进行自我欺骗。
    - 例如，如果一项研究中的所有学习率都太小，我们可能会错误地得出max_train_steps值非常大的结论。
    - 至少，我们应该检查研究中的最佳学习率是否不在搜索空间的边界处。

## 3.2 当训练受计算限制时，决定训练时间（步长）

1. 在某些情况下，训练损失会无限期地降低，我们的耐心和计算资源成为限制因素。
2. 如果训练损失（甚至验证损失）无限期地持续改善，我们是否应该尽可能长时间地培训？不一定
    1. 我们可以通过进行更多的更短的实验，并为我们希望推出的模型保留最长的“生产长度”，从而更有效地进行调整。
    2. 随着试验的训练时间接近我们的耐心极限，调谐实验对我们潜在的发射候选变得更加重要，但我们可以完成的实验更少。
    3. 在只训练约10%的生产长度时，我们可能会回答很多问题，但我们在这个时间限制下的结论总是有可能不适用于20%生产长度的实验，更不用说100%。
3. 多轮调整，增加每次试验的训练步长限制是一种明智的方法
    - 我们可以多次运行试验，通常运行1-3次。
    - 从本质上讲，尝试使用具有非常快周转时间的试验可以尽可能多地了解问题，在与最终最长运行相关的彻底性之间进行权衡。
    - 一旦给定的每次试验时间限制产生了有用的见解，我们就可以增加训练时间并继续调整，根据需要再次检查短期试验的结论。
4. 作为起始点, 我们建议进行两轮调整:
    - Round 1: 更短的运行时间可以找到好的模型和优化器超参数。
    - Round 2: 在好的超参数点上很少长时间运行以获得最终模型。
5. 调整学习率的衰减是从 Round i → Round i+1 的最大问题
    - 在两轮之间调整学习率计划时，一个常见的陷阱是使用学习率太小的所有额外训练步骤。

### Round 1

1. 不幸的是, 不能保证在短时间找到良好的超参数，当训练长度显著增加时，不完全训练仍然是良好的选择。然而，对于某些类型的超参数，通常足以使第1轮有用就能找到较好超参数。
2. 在快速训练中哪些超参数，我们希望改用更长的训练？对于这些，我们需要更多的研究。 但根据我们目前所知，以下是作者的怀疑，按照转移概率的降低顺序
    1. Very likely to transfer
        - 早期训练不稳定性可以在第一轮调整中使用较少数量的训练步骤来解决。也许这些超参数是最接近于我们所拥有的确定的转移赌注的东西。
            - `Warmup length`
            - `Initialization`
    2. Likely to transfer
        - 模型结构 - 模型架构中的戏剧性胜利通常会转移，但可能有很多反例。
    3. Might transfer
        - Optimization algorithm/optimizer hyperparameters - 我们认为这会“松散”地转移。它肯定比上面的东西弱
        - We think this would "loosely" transfer. It’s definitely weaker than the things above it.
        - Data augmentation
        - Regularization
            - 如果不可能完美地拟合训练集，则模型可能处于正则化不太可能有很大帮助的状态.
    4. Unlikely to transfer
        - Learning rate schedule: unlikely to transfer perfectly
            - [这篇论文](https://arxiv.org/abs/2203.15556)建议，甚至衰变时间表也可以改变，但我们不相信这在一般情况下是正确的。示例：在训练步骤的小#上调整sqrt衰减，然后扩展到大#将导致大多数训练发生在过小的步骤上。
                - 在极限训练预算的限制下，人们可能会在大多数训练计划中做得“足够好”，但如果进行调整，可能会看到明显的性能改善
            - 理解优化器的短期随机偏差，这预示着依赖此来进行学习率的调整是危险的

### Round 2

1. 使用Round 1产出的最佳超参数配置 
2. 使用较大学习率，进行额外的延长训练
    - 如果是`linear schedule`，则从第1轮开始保持衰变长度不变，并在开始时延长常数lr的周期
    - 对于`cosine decay`, 将Round 1的lr作为base，加长`max_train_steps` 和[Chinchilla paper](https://arxiv.org/abs/2203.15556)中一样
3. 对于具有非常成熟的建模和调优管道以及非常长且昂贵的生产训练运行的团队来说，更多的轮次可能是有意义的，但它们往往是过度的
    我们已经描述了如何从Step 1 → Step 2.如果我们不关心分析时间，如果高效利用计算是首要问题，那么理想的做法是在多轮不同的调整中以指数方式增加训练运行的长度（从而增加完成研究的端到端时间）。
        - 在每一轮中，我们都系统地确保我们的选择继续保持下去.
        - 从第i步到第i+1步，新的想法通过一条管道，通过越来越长时间的实验逐渐衍生出来。

