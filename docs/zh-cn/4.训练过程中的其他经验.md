# 4. 训练过程中的其他经验

## 4.1 优化输入管道

> 输入受限管道的原因和干预措施高度依赖于任务；使用探查器并查找常见问题。

1. 使用适当的探查器诊断输入绑定管道。例如，Perfetto For JAX或[TensorFlow profiler](https://www.tensorflow.org/guide/profiler) For TensorFlow。
2. 最终，具体原因和干预措施将高度依赖于任务。更广泛的工程考虑（例如最小化磁盘占用）可能会导致输入管道性能更差
3. Common causes:
    - 数据未与训练过程在同一位置，导致I/O延迟（这可能发生在通过网络读取训练数据时）。
    - 昂贵的在线数据预处理（考虑离线后进行并保存）。
    - 干扰数据管道预取的无意同步障碍。例如，在CommonLoopUtils（链接）中同步设备和主机之间的度量时。
4. Common tips:
    - 预取示例的仪器输入管道（例如tf.data.Dataset.petch）
    - 尽早从管道中删除未使用的功能/元数据。
    - 增加为输入管道生成示例的作业数的复制。例如，通过使用[tf.data](https://www.tensorflow.org/api_docs/python/tf/data/experimental/service)服务。


## 4.2 评估模型表现

> 用比训练时更大的`batch size`进行运行评估。以固定的步骤间隔（而不是固定的时间间隔）运行评估。


### 4.2.1 评估设置

1. 一些评估设置
   1. Online evaluation: 当模型在生产环境中提供预测时，收集度量。
   2. Offline evaluation: 当模型在代表生产环境的离线train/validation/test集上运行时，收集度量
   3. Periodic evaluations: 在模型训练期间收集度量，这些度量可能是离线评估的代理，和/或离线评估中使用的数据子集.
2. Online evaluation是核心指标，但在模型开发阶段通常是不切实际的。
3. 根据问题的不同，离线评估可能会相当复杂，计算成本也很高。
4. Periodic evaluations是最实用、最经济的选择，但可能不能完全代表生产环境。
   1. 我们在定期评估期间的目标是使用离线评估的权宜之计，而不牺牲我们在训练期间获得的信号的可靠性。

### 4.2.2 设置 periodic evaluations

1. 我们在训练期间运行定期评估，以实时监控其进度，以便于回顾性模型检查点选择，从而我们可以在训练结束时检查训练曲线。
2. 最简单的配置是在同一计算实例中执行训练和定期评估，定期在训练和评估之间交替进行。
    - 在此期间，模型评估使用的batch size至少要和训练的时候一样大，因为在评估期间不需要维护模型激活，从而降低了每个示例的计算要求。
3. Periodic evaluations应按常规步骤间隔进行，而不是按时间间隔进行
    - 基于时间间隔的评估可能会使解释训练曲线变得更加困难，特别是当训练可能会受到训练作业抢占、网络延迟问题等的影响时。
4. valid/test评估的周期性（当使用混洗的训练/验证/测试分割时）可能指示实现错误，例如测试数据与训练数据重叠，或训练数据未正确混洗。定期评估可以使这些问题更容易发现
5. 当评估集不能被batch size整除时，可能会出现部分批。确保填充示例正确称重，以防止损失函数受到其影响。通常，这些填充示例的权重可以为零。
6. 每次评估保存足够的信息以支持离线分析。理想情况下，我们将保存对单个示例的选择的预测，因为它们对调试非常有用。
    - 生成SavedModels这样的工件可以在评估作业完成后轻松地进行特殊模型检查。

### 4.2.3 选择一些样本进行 periodic evaluation

1. 定期评估用全部数据集会运行缓慢，所以一般都会抽样些数据进行定期评估
2. 在构建采样数据集时，我们考虑以下因素
    1. 采样大小(`Sample size`)
        - 检验在采样样本上的定期评估结果与整个数据离线评估结果基本一致。即在采样集和完整数据集之间没有偏斜。
        - 用于定期评估的数据集应足够小，以便很容易生成整个模型预测，但足够大，以便可以准确测量模型的改进（即不会被标签噪声淹没）
        - 它应该足够大，以适应顺序进行的多个此类评估，并仍能产生准确的估计。也就是说，<font color=darkred>避免在一段时间内自适应地“拟合”验证集，而不会将其推广到一个被搁置的测试集</font>。然而，这一考虑很少引起实际关注。
    2. 样本不平衡(`Imbalanced datasets`)
        - 对于不平衡的数据集，在罕见的示例类上的性能通常会很差。
        - 对于类标签中包含少量示例的数据集，记录正确预测的示例数量，以便更深入地了解准确性的提高（0.05灵敏度的提高听起来令人兴奋，但这仅仅是一个正确的示例吗？）。

## 4.3 保存检查点并回顾性地选择最佳检查点

> 进行固定步骤数的训练，并回顾性地从运行中选择最佳检查点

1. 大多是深度学习框架支持 model checkpointing. 也就是说，模型的当前状态定期保存在磁盘上。这使得训练工作能够适应计算实例中断。
2. 最好的checkpoint经常不是最后一个checkpoint, 特别是当验证集的表现不会随着时间的推移而继续增加，而是在特定值附近波动时
3. 设置管道，以跟踪训练期间迄今为止看到的N个最佳检查点。在训练结束时，模型选择就是选择训练过程中看到的最佳检查点。我们称之为回顾性最佳检查点选择（`retrospective optimal checkpoint selection`）。
4. early stopping通常是不必要的，因为我们预先指定了试验预算，并保留了迄今为止所见的N个最佳检查点。（这部分Andrew也有提到过）

## 4.3 设置实验跟踪

> 在跟踪不同的实验时，一定要注意一些要点，比如研究中检查点的最佳表现，以及研究的简短描述。

1. 我们发现，在电子表格中记录实验结果对我们所处理的各种建模问题很有帮助:
    - Study name
    - config 保存地址的链路
    - 对本次Study的简单描述
    - 试运行次数
    - 研究中最佳checkpoint在验证集上的性能。
    - 关于启动训练所需的未提交更改的特定复制命令或注释
2. 找一个追踪系统，它至少能捕捉到上面列出的信息，而且对人们来说很方便。

## 4.4 `Batch normalization`实施细节

> 如今，batch norm经常会被LayerNorm替代，但在无法替换的情况下，在更改`batch size`或主机数量时会出现一些棘手的细节。

1. Batch norm normalizes 使用当前batch的均值和方差, 但是在设置多设备下运行，除非明确同步，否则在每个设备上设置这些统计信息是不同的。
2. 轶事报道（主要在ImageNet上）说，仅使用约64个示例计算这些标准化统计数据实际上在实践中效果更好（参见本文中的[Ghost Batch Norm](https://arxiv.org/abs/1705.08741)）。
3. 将总批量大小与用于计算批量规范统计的示例数量解耦对于批量大小比较特别有用。
4. Ghost批处理规范实现并不总是正确处理每设备批处理大小>虚拟批处理大小的情况。在这种情况下，我们实际上需要对每个设备上的批次进行二次采样，以获得适当数量的批次规范统计示例。
5. 测试模式批处理规范中使用的指数移动平均值只是训练统计数据的线性组合，因此这些EMA只需要在保存到检查点之前进行同步。然而，批处理规范的一些常见实现不同步这些EMA，只保存来自第一个设备的EMA。

## 4.5 多主机管道的注意事项

> 对于日志记录、评估、RNG、检查点和数据分片，多主机训练可以很容易地引入错误

1. 确保训练pipline的日志和 checkpointing 在一个设备上。
2. 确保在运行评估或检查点之前，在主机之间同步批处理规范统计信息。
3. RNG seeds在主机之间相同（用于模型初始化），而在主机之间不同（用于数据混洗/预处理），这一点至关重要，因此请确保对它们进行适当标记。
4. 通常建议跨主机共享数据文件以提高性能。


